{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dac196/VisionComputer/blob/main/Red_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaCPza8Ru56D",
        "outputId": "fe0f064d-e446-4151-bfc1-244146ec987d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcirQKv9vVt8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKasJMWevd5f"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/My\\ Drive/Red_GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1J1DTk_zz_6"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import Dense, Conv2DTranspose, LeakyReLU, Reshape, BatchNormalization, Activation, Conv2D\n",
        "from keras.models import Model, Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.datasets import cifar10\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smAAbFzIzw5a"
      },
      "outputs": [],
      "source": [
        "def generador_de_imagenes():\n",
        "    generador = Sequential()\n",
        "    generador.add(Dense(256*4*4, input_shape = (100,)))\n",
        "    #generador.add(BatchNormalization())\n",
        "    generador.add(LeakyReLU())\n",
        "    generador.add(Reshape((4,4,256)))\n",
        "    generador.add(Conv2DTranspose(128,kernel_size=3, strides=2, padding = \"same\"))\n",
        "    #generador.add(BatchNormalization())\n",
        "    generador.add(LeakyReLU(alpha=0.2))\n",
        "    generador.add(Conv2DTranspose(128,kernel_size=3, strides=2, padding = \"same\"))\n",
        "    #generador.add(BatchNormalization())\n",
        "    generador.add(LeakyReLU(alpha=0.2))\n",
        "    generador.add(Conv2DTranspose(128,kernel_size=3, strides=2, padding = \"same\"))\n",
        "    #generador.add(BatchNormalization())\n",
        "    generador.add(LeakyReLU(alpha=0.2))\n",
        "    generador.add(Conv2D(3,kernel_size=3, padding = \"same\", activation='tanh'))\n",
        "    return(generador)\n",
        "\n",
        "modelo_generador = generador_de_imagenes()\n",
        "modelo_generador.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACHaD3PA0K6e"
      },
      "outputs": [],
      "source": [
        "# Definir datos de entrada\n",
        "def generar_datos_entrada(n_muestras):\n",
        "  X = np.random.randn(100 * n_muestras)\n",
        "  X = X.reshape(n_muestras, 100)\n",
        "  return X\n",
        "\n",
        "def crear_datos_fake(modelo_generador, n_muestras):\n",
        "  input = generar_datos_entrada(n_muestras)\n",
        "  X = modelo_generador.predict(input)\n",
        "  y = np.zeros((n_muestras, 1))\n",
        "  return X,y\n",
        "\n",
        "numero_muestras = 4\n",
        "X,_ = crear_datos_fake(modelo_generador, numero_muestras)\n",
        "\n",
        "# Visualizamos resultados\n",
        "for i in range(numero_muestras):\n",
        "    plt.subplot(2, 2, 1 + i)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(X[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVe1yv-K2K83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d56c1a-399b-4d8c-c7b2-c5021fab1530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 4097      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 522,497\n",
            "Trainable params: 522,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "def discriminador_de_imagenes():\n",
        "    discriminador = Sequential()\n",
        "    discriminador.add(Conv2D(64, kernel_size=3, padding = \"same\", input_shape = (32,32,3)))\n",
        "    discriminador.add(LeakyReLU(alpha=0.2))\n",
        "    #discriminador.add(Dropout(0.2))\n",
        "    discriminador.add(Conv2D(128, kernel_size=3,strides=(2,2), padding = \"same\"))\n",
        "    discriminador.add(LeakyReLU(alpha=0.2))\n",
        "    #discriminador.add(Dropout(0.2))\n",
        "    discriminador.add(Conv2D(128, kernel_size=3,strides=(2,2), padding = \"same\"))\n",
        "    discriminador.add(LeakyReLU(alpha=0.2))\n",
        "    #discriminador.add(Dropout(0.2))\n",
        "    discriminador.add(Conv2D(256, kernel_size=3, strides=(2,2), padding = \"same\"))\n",
        "    discriminador.add(LeakyReLU(alpha=0.2))\n",
        "    #discriminador.add(Dropout(0.2))\n",
        "    discriminador.add(Flatten())\n",
        "    discriminador.add(Dropout(0.4))\n",
        "    discriminador.add(Dense(1, activation='sigmoid'))\n",
        "    opt = Adam(lr=0.0002 ,beta_1=0.5)\n",
        "    discriminador.compile(loss='binary_crossentropy', optimizer= opt , metrics = ['accuracy'])\n",
        "    return(discriminador)\n",
        "modelo_discriminador = discriminador_de_imagenes()\n",
        "modelo_discriminador.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iqiEMee2Vbc"
      },
      "outputs": [],
      "source": [
        "def cargar_imagenes():\n",
        "    (Xtrain, Ytrain), (_, _) = cifar10.load_data()\n",
        "\n",
        "    # Nos quedamos con los perros\n",
        "    indice = np.where(Ytrain == 0)\n",
        "    indice = indice[0]\n",
        "    Xtrain = Xtrain[indice, :,:,:]\n",
        "\n",
        "    # Normalizamos los datos\n",
        "    X = Xtrain.astype('float32')\n",
        "    X = (X - 127.5) / 127.5\n",
        "\n",
        "    return X\n",
        "\n",
        "print(cargar_imagenes().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajEk7b3V3IQJ"
      },
      "outputs": [],
      "source": [
        "def cargar_datos_reales(dataset, n_muestras):\n",
        "  ix = np.random.randint(0, dataset.shape[0], n_muestras)\n",
        "  X = dataset[ix]\n",
        "  y = np.ones((n_muestras, 1))\n",
        "  return X,y\n",
        "\n",
        "def cargar_datos_fake(n_muestras):\n",
        "  X = np.random.rand(32 * 32 * 3 * n_muestras)\n",
        "  X = -1 + X * 2\n",
        "  X = X.reshape((n_muestras, 32,32,3))\n",
        "  y = np.zeros((n_muestras, 1))\n",
        "  return X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N91prYTz3dQR"
      },
      "outputs": [],
      "source": [
        "def entrenar_discriminador(modelo, dataset, n_iteraciones=20, batch = 128):\n",
        "  medio_batch = int(batch/2)\n",
        "\n",
        "  for i in range(n_iteraciones):\n",
        "    X_real, y_real = cargar_datos_reales(dataset, medio_batch)\n",
        "    _, acc_real = modelo.train_on_batch(X_real, y_real)\n",
        "\n",
        "    X_fake, y_fake = cargar_datos_fake(medio_batch)\n",
        "    _, acc_fake = modelo.train_on_batch(X_fake, y_fake)\n",
        "\n",
        "    print(str(i+1) + ' Real:' + str(acc_real*100) + ', Fake:' + str(acc_fake*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqZRDfQd3h0J"
      },
      "outputs": [],
      "source": [
        "dataset = cargar_imagenes()\n",
        "entrenar_discriminador(modelo_discriminador, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8ogfqen4QgA"
      },
      "outputs": [],
      "source": [
        "def crear_gan(discriminador, generador):\n",
        "    discriminador.trainable=False\n",
        "    gan = Sequential()\n",
        "    gan.add(generador)\n",
        "    gan.add(discriminador)\n",
        "\n",
        "    opt = Adam(lr=0.0002,beta_1=0.5)\n",
        "    gan.compile(loss = \"binary_crossentropy\", optimizer = opt)\n",
        "\n",
        "    return gan\n",
        "\n",
        "gan = crear_gan(modelo_discriminador,modelo_generador)\n",
        "gan.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nMRUpCk39DI"
      },
      "outputs": [],
      "source": [
        "def mostrar_imagenes_generadas(datos_fake, epoch):\n",
        "\n",
        "  now = datetime.now()\n",
        "  now = now.strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "  # Hacemos que los datos vayan de 0 a 1\n",
        "  datos_fake = (datos_fake + 1) / 2.0\n",
        "\n",
        "  for i in range(10):\n",
        "    plt.imshow(datos_fake[i])\n",
        "    plt.axis('off')\n",
        "    nombre = str(epoch) + '_imagen_generada_' + str(i) + '.png'\n",
        "    plt.savefig(nombre, bbox_inches='tight')\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oct3-PBR5nb0"
      },
      "outputs": [],
      "source": [
        "def evaluar_y_guardar(modelo_generador, epoch, medio_dataset):\n",
        "\n",
        "  # Guardamos el modelo\n",
        "  now = datetime.now()\n",
        "  now = now.strftime(\"%Y%m%d_%H%M%S\")\n",
        "  nombre = str(epoch) + '_' + str(now)+\"_modelo_generador_\" + '.h5'\n",
        "  modelo_generador.save(nombre)\n",
        "\n",
        "  # Generamos nuevos datos\n",
        "  X_real,Y_real = cargar_datos_reales(dataset, medio_dataset)\n",
        "  X_fake, Y_fake =  crear_datos_fake(modelo_generador,medio_dataset)\n",
        "\n",
        "  # Evaluamos el modelo\n",
        "  _, acc_real = modelo_discriminador.evaluate(X_real, Y_real)\n",
        "  _, acc_fake = modelo_discriminador.evaluate(X_fake, Y_fake)\n",
        "\n",
        "  print('Acc Real:' + str(acc_real*100) + '% Acc Fake:' + str(acc_fake*100)+'%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9yQ57xQ5osg"
      },
      "outputs": [],
      "source": [
        "def entrenamiento(datos, modelo_generador, modelo_discriminador, epochs, n_batch, inicio = 0):\n",
        "  dimension_batch = int(datos.shape[0]/n_batch)\n",
        "  medio_dataset = int(n_batch/2)\n",
        "\n",
        "  # Iteramos para todos los epochs\n",
        "  for epoch in range(inicio, inicio + epochs):\n",
        "    # Iteramos para todos los batches\n",
        "    for batch in range(n_batch):\n",
        "\n",
        "      # Cargamos datos reales\n",
        "      X_real,Y_real = cargar_datos_reales(dataset, medio_dataset)\n",
        "\n",
        "\n",
        "      # Enrenamos discriminador con datos reales\n",
        "      coste_discriminador_real, _ = modelo_discriminador.train_on_batch(X_real, Y_real)\n",
        "      X_fake, Y_fake =  crear_datos_fake(modelo_generador,medio_dataset)\n",
        "\n",
        "      coste_discriminador_fake, _ = modelo_discriminador.train_on_batch(X_fake, Y_fake)\n",
        "\n",
        "      # Generamos datos de entadas de la GAN\n",
        "      X_gan = generar_datos_entrada(medio_dataset)\n",
        "      Y_gan = np.ones((medio_dataset, 1))\n",
        "\n",
        "      # Entrenamos la GAN con datos falsos\n",
        "      coste_gan = gan.train_on_batch(X_gan, Y_gan)\n",
        "\n",
        "    # Cada 10 Epochs mostramos resultados y el coste\n",
        "    if (epoch+1) % 10 == 0:\n",
        "      evaluar_y_guardar(modelo_generador,epoch = epoch, medio_dataset= medio_dataset)\n",
        "      mostrar_imagenes_generadas(X_fake, epoch = epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q9IQx7w5wAa"
      },
      "outputs": [],
      "source": [
        "entrenamiento(dataset, modelo_generador, modelo_discriminador, epochs = 300, n_batch=128, inicio = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Infografia\n",
        "https://anderfernandez.com/blog/como-crear-una-red-generativa-antagonica-gan-en-python/\n",
        "\n",
        "Enlace donde se crearon las imagenes\n",
        "https://drive.google.com/drive/folders/1-3W1lg4G093uHW2xV9Epxu2pc2OEZIBj?usp=sharing"
      ],
      "metadata": {
        "id": "77EtRAM3xz17"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}